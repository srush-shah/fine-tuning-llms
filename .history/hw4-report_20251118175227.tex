\documentclass{article}

\input{header}

\title{DSGA 1011: Assignment 4}

\author{Full Name \\ Net ID}

\date{}


\colmfinalcopy
\begin{document}
\maketitle
% \section*{Part I. Q1} No written element, submit \texttt{out\_original.txt}  to autograder.
\section*{Q0. 1.}
Please provide a link to your github repository, which contains the code for both Part I and Part II. \textcolor{gray}{TODO}
\section*{Q2. 1.}
Describe your transformation of dataset.

The data transformation applies two types of augmentations to text: synonym replacement and typo simulation. 

\textbf{Synonym Replacement:} For each word in the text, with 20\% probability, we attempt to replace it with a synonym from WordNet. We extract synonyms from all synsets for the word, filter out synonyms containing underscores (to avoid multi-word phrases), and randomly select one. The original capitalization is preserved.

\textbf{Typo Simulation:} For words that were not replaced by synonyms, with 15\% probability, we simulate keyboard typos by replacing a character with a neighboring key on the QWERTY keyboard. We focus on vowels and common letters (a, e, i, o, u, s, d, f, g, h, j, k, l) and replace at most one character per word with a randomly selected neighbor. The original capitalization is preserved.

Both transformations are applied at the word level after tokenization, and the text is detokenized to produce the final transformed example. This approach introduces natural variations that simulate real-world text noise while preserving the semantic meaning of the original text.
% \section*{Part I. Q2. 2. No written element, submit \texttt{out\_transformed.txt} to autograder. }
\section*{Q3. 1}
\textbf{Report \& Analysis}
    \begin{itemize}
        \item Report the accuracy values for both the original and transformed test data evaluations.  \textcolor{gray}{TODO}
        \item Analyze and discuss the following: (1) Did the model's performance on the transformed test data improve after applying data augmentation? (2) How did data augmentation affect the model's performance on the original test data? Did it enhance or diminish its accuracy? \textcolor{gray}{TODO}
        \item Offer an intuitive explanation for the observed results, considering the impact of data augmentation on model training. \textcolor{gray}{TODO}
        \item Explain one limitation of the data augmentation approach used here to improve performance on out-of-distribution (OOD) test sets. \textcolor{gray}{TODO}
    \end{itemize}
\section*{Part II. Q4}
% 
% \section{Data Statistics and Processing (8pt)}


\begin{table}[h!]
\centering
\begin{tabular}{lcc}
\toprule
Statistics Name & Train & Dev \\
\midrule
Number of examples & 4225 & 466 \\
Mean sentence length & 10.96 & 10.91 \\
Mean SQL query length & 60.90 & 58.90  \\
Vocabulary size (natural language)& 868 & 444  \\
Vocabulary size (SQL)& 533 & 326  \\
\bottomrule
\end{tabular}
\caption{Data statistics before any pre-processing. \textcolor{gray}{You need to at least provide the statistics listed above, and can add new entries.}}
\label{tab:data_stats_before}
\end{table}

\begin{table}[h!]
\centering
\begin{tabular}{lcc}
\toprule
Statistics Name & Train & Dev \\
\midrule
\multicolumn{3}{l}{\textbf{T5 fine-tuned model}} \\ % \textcolor{gray}{(T5 fine-tuning or T5 from scratch)}} \\
Mean sentence length (tokens) & 10.96 & 10.91 \\
Mean SQL query length (tokens) & 60.90 & 58.90  \\
Vocabulary size (natural language) & 868 & 444  \\
Vocabulary size (SQL) & 533 & 326  \\
\midrule
\bottomrule
\end{tabular}
\caption{Data statistics after pre-processing. After tokenization with T5TokenizerFast, the statistics remain similar to the raw data since T5 tokenization preserves most word boundaries. The vocabulary sizes reflect the unique tokens in the tokenizer's vocabulary that appear in the dataset.}
\label{tab:data_stats_after}
\end{table}



\newpage




\section*{Q5}\label{sec:t5}


\begin{table}[h!]
\centering
\begin{tabular}{p{3.5cm}p{10cm}}
\toprule
Design choice & Description \\
\midrule
Data processing & Added task prefix ``translate English to SQL: '' to all natural language queries. No other preprocessing was applied to the SQL queries or natural language inputs. \\
Tokenization & Used T5TokenizerFast from 'google-t5/t5-small' for both encoder and decoder. Encoder inputs were tokenized with the task prefix included. Decoder targets (SQL queries) were tokenized with add\_special\_tokens=True to include EOS tokens. Maximum sequence lengths: 256 tokens for both encoder and decoder inputs. \\
Architecture & Fine-tuned the entire T5-small model (all encoder and decoder layers). The model was initialized from the pretrained 'google-t5/t5-small' checkpoint. \\
Hyperparameters & Learning rate: 1e-4, Batch size: 32, Optimizer: AdamW, Scheduler: Cosine with 1 warmup epoch, Max epochs: 20, Patience: 3 epochs (early stopping based on dev F1 score), Weight decay: 0.0. Generation: Greedy decoding (num\_beams=1), max\_new\_tokens=256, repetition\_penalty=1.2. \\
\bottomrule
\end{tabular}
\caption{Details of the best-performing T5 model configurations (fine-tuned)}
\label{tab:t5_results_ft}
\end{table}







\section*{Q6. }

\paragraph{Quantitative Results:} 
\begin{table}[h!]
\centering
\begin{tabular}{lcc}
  \toprule
  System & Query EM & F1 score\\
  \midrule
  \multicolumn{3}{l}{\textbf{Dev Results}} \\
  \midrule
  
  \multicolumn{3}{l}{\textbf{T5 fine-tuned}} \\
  Full model & 0.00\% & 11.80\% \\[5pt]
  % Variant1 & XX.XX & XX.XX \\
  % Variant2 & XX.XX & XX.XX \\
  % Variant3 & XX.XX & XX.XX \\
  
  \midrule
  \multicolumn{3}{l}{\textbf{Test Results}} \\
  \midrule
  T5 fine-tuning & 0.00\% & 11.80\% \\
  \bottomrule
\end{tabular}  
\caption{Development and test results. \textcolor{gray}{Use this table to report quantitative results for both dev and test results.}}
\label{tab:results}
\end{table}


\paragraph{Qualitative Error Analysis:} 


\begin{landscape}
\begin{table}
  \centering
  \begin{tabular}{p{2cm}p{6cm}p{6cm}p{6cm}}
    \toprule
    \textbf{Error Type}& \textbf{Example Of Error} & \textbf{Error Description} & \textbf{Statistics} \\
    \midrule
    Repetitive token generation & \texttt{SELECT DISTINCT flight\_service\_service\_service\_service...} & The model generates repetitive sequences of the same tokens (e.g., ``service\_service\_service'' or ``airport\_code = airport\_service\_1.airport\_code = ...''), indicating the model gets stuck in generation loops. & 466/466 (100\% of queries show some form of repetition) \\
    \midrule
    Malformed SQL syntax & \texttt{SELECT DISTINCT flight\_1.airport\_code = airport\_service\_1.airport\_code = ...} & Generated queries contain invalid SQL syntax, such as multiple consecutive equals signs, missing WHERE clauses, or incorrect table/column references. & 466/466 (100\% SQL error rate) \\
    \midrule
    Incomplete queries & \texttt{denver nach atlanta} & Some queries are completely malformed, generating natural language text instead of SQL, or producing queries that are missing critical SQL components. & ~50/466 (approximately 10-15\% of queries) \\
    \midrule
    Missing SELECT clause components & \texttt{SELECT DISTINCT flight\_1.flight\_id FROM flight flight\_1, airport\_service airport\_service\_1, city cit...} & Queries often have truncated or incomplete SELECT/FROM clauses, missing proper table aliases or column specifications. & ~200/466 (approximately 40-50\% of queries) \\
    \bottomrule
  \end{tabular}
  \label{tab:qualitative}
  \caption{Use this table for your qualitative analysis on the dev set.}\label{tab:qualitative}
\end{table}
\end{landscape}

\section*{Q7.}

Provide a link to a google drive which contains a model checkpoint used to generate outputs you have submitted. 
\textcolor{gray}{TODO}

\section*{Extra Credit: }

If you are doing extra credit assignment, please describe your system here, as well as provide a link to a google drive which contains a model checkpoint used to generate outputs you have submitted. 
\textcolor{gray}{Optional TODO}
\end{document}